---
title: "SAMHSA NSSATS modeling and formal testing "
output: html_notebook
---


Checking assumptions of linear regression: normal distribution and continuous variable


```{r}
#all of the forprofit distributions are skewed right 
hist(state_final_df$Forprofit, 
     xlab = "Number of Treatment Centers", 
     main = "For-Profit Treatment Center Distribution")

#add the mean and variance onto the plot
text(600,150,paste("mean = ", round(mean(state_final_df$Forprofit), 2), "\n variance = ", round(var(state_final_df$Forprofit),2)))

#all of the nonprofit distributions are skewed right
hist(state_final_df$Nonprofit, xlab = "Number of Treatment Centers", main = "Non-Profit Treatment Center Distribution")
#add the mean and variance onto the plot
text(600,120,paste("mean = ", round(mean(state_final_df$Nonprofit), 2), "\n variance = ", round(var(state_final_df$Nonprofit),2)))

#all of the government distributions are skewed right
hist(state_final_df$Government, xlab = "Number of Treatment Centers", main = "Government Treatment Center Distribution")
#add the mean and variance onto the plot
text(150,120,paste("mean = ", round(mean(state_final_df$Government, na.rm = TRUE), 2), "\n variance = ", round(var(state_final_df$Government, na.rm = TRUE),2)))


```


For count data, we have options of poisson or negative binomial distributions. 

Negative binomial distribution is appropriate if there is sparse data (not applicable) or overdispersion (variance > mean)
```{r}
print("For Profit Overdispersion")
var(profit_states_1419$count_Forprofit_2015) > mean(profit_states_1419$count_Forprofit_2015)
var(profit_states_1419$count_Forprofit_2016) > mean(profit_states_1419$count_Forprofit_2016)
var(profit_states_1419$count_Forprofit_2017) > mean(profit_states_1419$count_Forprofit_2017)
var(profit_states_1419$count_Forprofit_2018) > mean(profit_states_1419$count_Forprofit_2018)
var(profit_states_1419$count_Forprofit_2019) > mean(profit_states_1419$count_Forprofit_2019)

print("Non Profit Overdispersion")
var(profit_states_1419$count_Nonprofit_2015) > mean(profit_states_1419$count_Nonprofit_2015)
var(profit_states_1419$count_Nonprofit_2016) > mean(profit_states_1419$count_Nonprofit_2016)
var(profit_states_1419$count_Nonprofit_2017) > mean(profit_states_1419$count_Nonprofit_2017)
var(profit_states_1419$count_Nonprofit_2018) > mean(profit_states_1419$count_Nonprofit_2018)
var(profit_states_1419$count_Nonprofit_2019) > mean(profit_states_1419$count_Nonprofit_2019)

print("Government Overdispersion")
var(profit_states_1419$count_Government_2015) > mean(profit_states_1419$count_Government_2015)
var(profit_states_1419$count_Government_2016) > mean(profit_states_1419$count_Government_2016)
var(profit_states_1419$count_Government_2017, na.rm = TRUE) > mean(profit_states_1419$count_Government_2017, na.rm = TRUE) #there is 1 null value in this data 
var(profit_states_1419$count_Government_2018) > mean(profit_states_1419$count_Government_2018)
var(profit_states_1419$count_Government_2019) > mean(profit_states_1419$count_Government_2019)


```


```{r LRT for best demand variables }
library(lme4)
#code to determine the best subset of demand variables to include 
demandvars_lrt <- function(df, demandvars_list, verbose = FALSE){
  
  model_list <- list()
  
  #loop through to peel off the last element from demandvars_list at a time, until only the first demand variable is left 
  for(i in 0:(length(demandvars_list)-1))
  {
    demand_variables_touse <- demandvars_list[1:(length(demandvars_list) - i)]
    
    #create the list of demand variables to use 
    demand_vars <- paste(demand_variables_touse, collapse = " + ")
  
    control_vars <- " + medicaid_enroll_percapita + 
             percapita_health_spending_thousands + 
             pop_millions +
             (1|State_Name) + (1 | year )"
    
    #paste the formula together 
    nb_formula <- formula(paste("count_tx ~", demand_vars, control_vars))
    
    #build the model and save in the list
    model <- glmer.nb(nb_formula, data = df, 
                      control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)))
    
    #append the model to the list 
    model_list[[i + 1]] <- model

  }
  
  #store the maximum likelihood model - start by assuming it is the full model 
  max_model <- model_list[[1]]
  
  #compare the models pairwise using the LRT 
  for (i in seq(1:(length(model_list) - 1) ))
  {
      anova_results <- anova(max_model, model_list[[i+1]])
      
      if (verbose)
      {
        print("________________RESULTS_________________")
        print(anova_results)
      }
      
      #get the p-value
      pval <- anova_results$'Pr(>Chisq)'[2]
      
      if (pval < 0.05)
      {
        print(paste("The more complex model improves fit sufficiently, p = ", pval))
      }
      else
      {
        print(paste("The more complex model does not improve fit sufficiently. considering the less complex model to be better", p = pval))
        max_model <- model_list[[i+1]]
      }
      
      print("Best model so far includes: ")
      print(all.vars(formula(max_model)))
  }
}

```


```{r LRT for best control variables, given best demand variables}
#code to determine the best subset of demand variables to include 
controlvars_lrt <- function(df, bestdemandvars_str, controlvars_list, verbose = FALSE){
  
  model_list <- list()
  
  #loop through to peel off the last element from controlvars_list at a time, until only the first control variable is left 
  for(i in 0:(length(controlvars_list) - 1 ))
  {
    control_variables_touse <- controlvars_list[1:(length(controlvars_list) - i)]
    
    #create the list of control variables to use 
    control_vars <- paste(control_variables_touse, collapse = " + ")
  
    random_effects <- " +
             (1|State_Name) + (1 | year) "
    
    #paste the formula together 
    nb_formula <- formula(paste("count_tx ~", bestdemandvars_str, control_vars, random_effects))

    #build the model and save in the list
    model <- glmer.nb(nb_formula, data = df, 
                      control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)))
    
    #append the model to the list 
    model_list[[i + 1]] <- model

  }
  

  #store the maximum likelihood model - start by assuming it is the full model 
  max_model <- model_list[[1]]
  
  #compare the models pairwise using the LRT 
  for (i in seq(1:(length(model_list) - 1) ))
  {
      anova_results <- anova(max_model, model_list[[i+1]])
      
      #get the p-value
      pval <- anova_results$'Pr(>Chisq)'[2]
      
      if (verbose)
      {
        print("________________RESULTS_________________")
        print(anova_results)
      }
      
      if (pval < 0.05)
      {
        print(paste("The more complex model improves fit sufficiently, p = ", pval))
      }
      else
      {
        print(paste("The more complex model does not improve fit sufficiently. considering the less complex model to be better", p = pval))
        max_model <- model_list[[i+1]]
      }
      
      print("Best model so far includes: ")
      print(all.vars(formula(max_model)))
  }
}
```



Uninsured rate is negatively correlated with a lot of things (medicaid enrollment, income)- let's remove
```{r}
library(corrplot)
corr_matrix <- cor(state_final_df[, c("pop_millions", "percapita_health_spending_thousands", "medicaid_enroll_percapita", "prev2years_drugusecalc", "prev2years_aud", "prev2years_marijuana", "Gender_Male", "Ethnicity_HispanicorLatino", "Race_White", "Insurance_Uninsured", "Unemployment", "Income")])

colnames(corr_matrix) <- c("Population in Millions", "Percapita Health Spending", "Percapita Medicaid Enrollment", "Lagged Drug Use", "Lagged AUD", "Lagged Marijuana Use", "Male", "Hispanic", "White Race", "Uninsured", "Unemployment", "Income")
rownames(corr_matrix) <- c("Population in Millions", "Percapita Health Spending", "Percapita Medicaid Enrollment", "Lagged Drug Use", "Lagged AUD", "Lagged Marijuana Use", "Male", "Hispanic", "White Race", "Uninsured", "Unemployment", "Income")

write.csv(corr_matrix, "correlation_matrix.csv")
corrplot(corr_matrix, method="circle")
corr_matrix
```

Create a summary table of all the variables we want to investigate
```{r create summary table 1}
data.frame(descr(state_final_df, show=c("n", "NA.prc", "mean", "sd", "range"))) %>%
  separate(range, into = c("range", "min_max"), sep = " ") %>%
  mutate(min_max = gsub("[\\(\\)]", "", min_max)) %>%
  separate(min_max, into = c("min", "max"), sep = "-") %>%
  select(-range) %>%
  mutate(min=as.numeric(min), max = as.numeric(max),
         mean = round(mean, 2),
         sd = round(sd, 2)) %>%
  write.csv("Data/CleanData/SummaryStatistics.csv", row.names = FALSE)

```



FOR PROFIT MODEL
```{r}
demandvars_lrt(state_forprofit, c("prev2years_drugusecalc", "prev2years_aud", "prev2years_marijuana"), verbose = TRUE)
```

```{r}
controlvars_lrt(state_forprofit, "prev2years_drugusecalc + prev2years_aud + ", c("pop_millions",  "percapita_health_spending_thousands", "medicaid_enroll_percapita"), verbose = TRUE)
```


relationship is not significant when adding cocaine and heroin separately
```{r previous for profit model with only a few covariates}
# glmer_forprofit <- glmer.nb(count_tx ~ #prev2years_cocaine +  prev2years_heroin +  prev2years_aud + 
#                                  prev2years_drugusecalc + prev2years_aud + #prev2years_marijuana +
#                                 pop_millions + #percapita_health_spending_thousands + medicaid_enroll_percapita + 
#                                 (1|State_Name)+ (1 | year),
#                               control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
#                               data = state_forprofit)
# 
# summary(glmer_forprofit)
# confint(glmer_forprofit)

```

#drug policy is covered by state fixed effects
#mental health services would be a whole separate project
#we dont have info on urbanization, education level, crime rates now
```{r try a model with more control variables}

# more_controls_formula <- formula("count_tx ~ prev2years_aud + prev2years_drugusecalc + 
#                                 scale(pop_millions) + 
#                                 scale(Income) +
#                                 scale(medicaid_enroll_percapita) +
#                                 scale(Gender_Male) +
#                                 scale(Unemployment) + 
#                                 scale(percapita_health_spending_thousands) +
#                                 scale(Insurance_Uninsured) + 
#                                 scale(Ethnicity_HispanicorLatino) + 
#                                 scale(Race_White) +
#                                 (1| State_Name) + (1 | year)")

more_controls_str <- "~ prev2years_aud + prev2years_drugusecalc + 
                                scale(pop_millions) + 
                                scale(Income) +
                                scale(medicaid_enroll_percapita) +
                                scale(Gender_Male) +
                                scale(Unemployment) + 
                                scale(percapita_health_spending_thousands) +
                                scale(Insurance_Uninsured) + 
                                scale(Ethnicity_HispanicorLatino) + 
                                scale(Race_White) +
                                (1| State_Name) + (1 | year)"

#glmer_forprofit <- glmer.nb(more_controls_formula, control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
#                               data = state_forprofit)
glmer_forprofit <- glmer.nb(formula(paste("Forprofit", more_controls_str)), control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
                               data = state_final_df)

summary(glmer_forprofit)
```


```{r those variables dont seem to improve the fit much but we can use them}
controlvars_lrt(state_forprofit, "prev2years_drugusecalc + prev2years_aud + ", c("scale(pop_millions)",  
                                                                                 "scale(Race_White)", "scale(Gender_Male)", "scale(Ethnicity_HispanicorLatino)",
                                                                                 "scale(percapita_health_spending_thousands)", "scale(medicaid_enroll_percapita)", 
                                                                                 "scale(Income)", "scale(Unemployment)"
                                                                                 ), verbose = TRUE)
```





NON PROFIT MODEL
```{r find best set of variables for the nonprofit model}
demandvars_lrt(state_nonprofit, c("prev2years_drugusecalc", "prev2years_aud", "prev2years_marijuana"), verbose = TRUE)
```


```{r}
controlvars_lrt(state_nonprofit, "prev2years_drugusecalc + prev2years_aud + ", c("pop_millions", "medicaid_enroll_percapita", "percapita_health_spending_thousands"))
```


```{r previous nonprofit model with few covariates}
# glmer_nonprofit <- glmer.nb(count_tx ~ prev2years_drugusecalc + prev2years_aud + #prev2years_marijuana +
#                                 pop_millions + #percapita_health_spending_thousands + medicaid_enroll_percapita + 
#                                 (1|State_Name)+ (1 | year),
#                               control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
#                               data = state_nonprofit)
# 
# summary(glmer_nonprofit)
```


```{r fit a model for nonprofit with all control variables}
glmer_nonprofit <- glmer.nb(formula(paste("Nonprofit", more_controls_str)), control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
                            data = state_final_df)

summary(glmer_nonprofit)
```

Because the above threw convergence errors, running allFit
```{r}
summary(allFit(glmer_nonprofit))
```




GOVERNMENT MODEL
```{r}
demandvars_lrt(state_govt, c("prev2years_drugusecalc", "prev2years_aud", "prev2years_marijuana"))
```


```{r}
controlvars_lrt(state_govt, "prev2years_drugusecalc + prev2years_aud + ", c("pop_millions", "medicaid_enroll_percapita", "percapita_health_spending_thousands"))
```



```{r previous govt model with few covariates}
# glmer_govt <- glmer.nb(count_tx ~ prev2years_drugusecalc + prev2years_aud + #prev2years_marijuana +
#                                 pop_millions + #percapita_health_spending_thousands + medicaid_enroll_percapita + 
#                                 (1|State_Name) + (1 | year),
#                               control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
#                               data = state_govt)
# 
# summary(glmer_govt)
# confint(glmer_govt)
```



```{r fit a model with all control variables for govt}
glmer_govt <- glmer.nb(formula(paste("Government", more_controls_str)), control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
                               data = state_final_df)

summary(glmer_govt)
```


```{r allFit checks if other convergence methods get the same result}
summary(allFit(glmer_govt))

```



MODEL ON ALL TREATMENT CENTERS
```{r fit a model on all treatment centers}
glmer_all <- glmer.nb(formula(paste("count_tx_total", more_controls_str)), control = glmerControl(optimizer = "bobyqa", optCtrl = list(maxfun = 2e6)),
                               data = state_final_df)

summary(glmer_all)
```



Plot
```{r function to create a map of state random effects}
library(ggplot2)
library(maps)
library(mapdata)
library(plotly)
library(sf)
library(usmap)

usa <- map_data('usa')
state <- map_data("state")


map_randomeffects <- function(model, title)
{
  #create the dataset 
  state_randomeffects <- ranef(model)$State_Name
  #relabel the dataframe
  state_randomeffects <- data.frame("State_Name" =row.names(state_randomeffects), "Intercept" = state_randomeffects[,"(Intercept)"])

  #create the map
  state_data_inc_alaska <- state_randomeffects %>%
  mutate(fips = fips(State_Name))

  plot_usmap(data = state_data_inc_alaska, values = "Intercept", regions = "states", color = "grey") + #, labels = TRUE) + 
  scale_fill_gradient2(midpoint = 0, low = "red", mid = "grey", high = "green") +
                      ggtitle(paste('Random Effects per State in', title)) + 
                       #coord_fixed(1.3)
    theme(legend.position = "right")
}

map_randomeffects(glmer_forprofit, "For Profit Model")
map_randomeffects(glmer_nonprofit, "Non Profit Model")
map_randomeffects(glmer_govt, "Government Model")
map_randomeffects(glmer_all, "Overall Model")
```


```{r print coefficients in a handy table}
library(sjPlot)
library(sjmisc)
library(sjlabelled)
#tab_model

tab_model(glmer_all, glmer_forprofit, glmer_nonprofit, glmer_govt)
```



